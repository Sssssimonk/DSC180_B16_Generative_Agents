{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576f7ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time \n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e898eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 15:16:57.612412: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-21 15:16:57.660439: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import AutoModelForQuestionAnswering, AutoModelForCausalLM\n",
    "from transformers import AutoModel\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ffb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "apartment_graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0430427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_meta = '''{}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7826c0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45782629119148888c4826c1cac8dc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/j5xiao/.local/lib/python3.9/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "access_token = \"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\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",load_in_8bit=True,\n",
    "                                             token=access_token, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2fda35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, use_openai=False):\n",
    "    if use_openai:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "          model= \"gpt-3.5-turbo\",\n",
    "          messages=[\n",
    "            {\"role\":\"system\",\"content\":\"Please enter your question.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "          ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        message = completion.choices[0].message[\"content\"]\n",
    "        return message.strip()\n",
    "\n",
    "    else:\n",
    "        hf_generator = pipeline('text-generation', \n",
    "                                model=model, \n",
    "                                tokenizer=tokenizer)\n",
    "        \n",
    "        output = hf_generator(prompt, max_length=len(prompt)+128, do_sample=True)\n",
    "        out = output[0]['generated_text']\n",
    "        if '### Response:' in out:\n",
    "            out = out.split('### Response:')[1]\n",
    "        if '### Instruction:' in out:\n",
    "            out = out.split('### Instruction:')[0]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a3a277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 21 15:17:21 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.53       Driver Version: 525.53       CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:3E:00.0 Off |                  N/A |\r\n",
      "|  0%   44C    P2    58W / 250W |   2461MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:B1:00.0 Off |                  N/A |\r\n",
      "|  0%   37C    P2    56W / 250W |   2609MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:B2:00.0 Off |                  N/A |\r\n",
      "|  0%   39C    P2    58W / 250W |   2609MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:DA:00.0 Off |                  N/A |\r\n",
      "|  0%   33C    P2    55W / 250W |   3213MiB / 11264MiB |     12%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf1828c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# world_graph = nx.Graph()\n",
    "\n",
    "# prompt_meta = '''### Instruction:\n",
    "# {}\n",
    "\n",
    "# ### Response:'''\n",
    "\n",
    "# town_areas = [\"Barthen's Provisions\", \"Lionshield Coster\", \"Stonehill Inn\", \"Phandalin Town Square\"]\n",
    "# town_areas = {\"Phandalin Town Square\": 'Town square of the town of Phandalin.',\n",
    "#               'Stonehill Inn': \"In the center of town stands a large, newly built roadhouse of fieldstone and rough-hewn timbers. The common room is filled with locals nursing mugs of ale or cider, all of them eyeing you with curiosity.\",\n",
    "#               \"Barthen's Provisions\": \"Barthen’s is the biggest trading post in Phandalin. Its shelves stock most ordinary goods and supplies, including backpacks, bedrolls, rope, and rations. The place is open from sunup to sundown.\",\n",
    "#               \"Edermath Orchard\": \"A tidy little cottage beside an apple orchard.\",\n",
    "#               \"Lionshield Coster\": \"Hanging above the front door of this modest trading post is a sign shaped like a wooden shield with a blue lion painted on it. This building is owned by the Lionshields, a merchant company based in the city of Yartar, over a hundred miles to the east. They ship finished goods to Phandalin and other small settlements throughout the region, but this outpost has been hard hit by banditry. The most recent Lionshield caravan due in Phandalin never arrived.\",\n",
    "#               \"Phandalin Miner's Exchange\": \"The Miner’s Exchange is a trading post where local miners have their valuable finds weighed, measured, and paid out. In the absence of any local lord or authority, the exchange also serves as an unofficial records office, registering claims to various streams and excavations around the area. There isn’t any real gold rush in Phandalin, but enough wealth is hidden in the nearby streams and valleys to support a good number of independent prospectors. The exchange is a great place to meet people who spend a lot of time out and about in the countryside surrounding Phandalin. The guildmaster is an ambitious and calculating human woman named Halia Thornton.\",\n",
    "#               \"Alderleaf Farm\": \"A farm owned by the helpful halfling farmer, Qelline Alderleaf.\",\n",
    "#               \"Shrine of Luck\": \"Phandalin's only temple is a small shrine made of stones taken from the nearby ruins. It is dedicated to Tymora, goddess of luck and good fortune.\",\n",
    "#               \"The Sleeping Giant\": \"This rundown tap house is a dirty, dangerous watering hole at the end of Phandalin’s main street. It is frequented by Redbrand thugs and operated by a surly female dwarf named Grista.\",\n",
    "#               \"Townmaster’s Hall\": \"The townmaster’s hall has sturdy stone walls, a pitched wooden roof, and a bell tower at the back. Posted on a board next to the front door is a notice written in Common. It reads: “REWARD — Orcs near Wyvern Tor! Those of a mind to face the orc menace should inquire within.” The notice bears the town’s seal and an indecipherable signature.\",\n",
    "#               \"Tresendar Manor\": \"A ruined manor. The Redbrands’ base in Phandalin is a dungeon complex under Tresendar Manor. Before the manor was ruined, its cellars served as safe storage for food and water in the event that the estate was attacked, while an adjoining crypt provided a resting place for the deceased members of the Tresendar family. The Redbrands have since expanded the cellars to suit their own purposes, adding slave pens, workshops, and barracks.\"\n",
    "#               }\n",
    "# town_people = {\"Toblen Stonehill\": \"Toblen owns a trading post.\", \n",
    "#                \"Daran Edermath\": \"Daran is a retired adventurer who lives in a tidy little cottage beside an apple orchard. A fit, silver-haired half-elf well over a hundred years old, Daran is a fighter who served as a marshal and herald for many years in the lands of the Dragon Coast, far to the southeast. Upon retiring, he returned to the Neverwinter region, his original home.\",  \n",
    "#                \"Linene Graywind\": \"Linene runs a trading post.\",  \n",
    "#                \"Halia Thornton\": \"Halia is an ambitious and calculating human woman. She is the guildmaster of Phandalin Miner’s Exchange, a trading post where local miners have their valuable finds weighed, measured, and paid out. In her attempts to establish the Miner's Exchange as the closest thing the town has to a governing authority, she acts as more than a simple merchant.\",  \n",
    "#                \"Qelline Alderleaf\": \"Qelline is a wise female halfling of forty-five, and is a pragmatic farmer who seems to know everything that goes on in town. She is a kind host, and is willing to let the characters stay in her hayloft if they don't want to stay at the Stonehill Inn.\",  \n",
    "#                \"Sister Garaele\": \"Sister Garaele is an elf cleric of Tymora and a Harper agent.\", \n",
    "#                \"Harbin Wester\": \"Harbin is the townmaster of Phandalin. A pompous, old food. Phandalin has no functioning government, but the townsfolk elect someone to serve as townmaster each year. The townmaster serves as a judge in minor disputes and keeps any records that need to be kept.\",\n",
    "#                \"Terrill Bloodscar\": \"Terrill is a human ruffian. He wears a grimy scarlet cloak. He is a member of the Redbrand ruffians. He doesn't like adventurers, and wants to rob and kill them.\",\n",
    "#                \"Conrad Scarface\": \"Conrad is a human ruffian. He wears a grimy scarlet cloak. He is a member of the Redbrand ruffians. He doesn't like adventurers, and wants to rob and kill them.\",\n",
    "#                \"Nellie Starsmith\": \"Nellie is a human ruffian. She wears a grimy scarlet cloak. She is a member of the Redbrand ruffians. She doesn't like adventurers, and wants to rob and kill them.\",\n",
    "#                \"Valerie Grinblade\": \"Valerie is a human ruffian. She wears a grimy scarlet cloak. She is a member of the Redbrand ruffians. She doesn't like adventurers, and wants to rob and kill them.\",\n",
    "#                }\n",
    "# for town_area in town_areas.keys():\n",
    "#     world_graph.add_node(town_area)\n",
    "#     world_graph.add_edge(town_area, town_area)\n",
    "# for town_area in town_areas.keys():\n",
    "#     world_graph.add_edge(town_area, \"Phandalin Town Square\")\n",
    "# locations = {}\n",
    "# for i in town_people.keys():\n",
    "#     locations[i] = \"Phandalin Town Square\"\n",
    "\n",
    "\n",
    "# memories = {}\n",
    "# for i in town_people.keys():\n",
    "#     memories[i] = []\n",
    "# plans = {}\n",
    "# for i in town_people.keys():\n",
    "#     plans[i] = []\n",
    "\n",
    "# global_time = 8\n",
    "# def generate_description_of_area(x):\n",
    "#     text = \"It is \"+str(global_time)+\":00. The location is \"+x+\".\"\n",
    "    \n",
    "#     people = []\n",
    "#     for i in locations.keys():\n",
    "#         if locations[i] == x:\n",
    "#             people.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "668a3988",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_meta = '''### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a386d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "town_areas = {\n",
    "    \"Town Exit\": \"This is the only entrance and exit to the town.\",\n",
    "    \"Main Street\": \"This is the main road of the town, connecting the main buildings in the town.\",\n",
    "    \"Second Street\": \"This is a small road in the town, connecting residents' houses.\",\n",
    "    \"City Hall\": \"This is the administrative headquarters of a city or town,\" \\\n",
    "                + \" where town people hold meetings, Jack works here.\",\n",
    "    \"Police Office\": \"The town's security department maintains the safety of the town. Tom works here.\",\n",
    "    \"Park\": \"Ordinary town residents walk and play here, and gather here on weekends.\",\n",
    "    \"Supermarket\": \"Residents buy food here.\",\n",
    "    \"Jack's House\": \"It is the home of Jack, a small town resident.\" \\\n",
    "                + \" Jack will come back here to rest at night and go to work during the day.\",\n",
    "    \"Tom's House\": \"It is the home of Tom, a small town resident.\" \\\n",
    "                + \" Tom will come back here to rest at night and go to work during the day.\",\n",
    "    \"Lee's House\": \"It is the home of Lee, a small town resident.\" \\\n",
    "                + \" Lee will come back here to rest at night and go to work during the day.\"\n",
    "}\n",
    "town_people = {\n",
    "    \"Jack\": \"Jack is a government employee. He usually works in City \" \\\n",
    "                + \"Hall and sometimes goes to other places for inspections. \" \\\n",
    "                + \"He works Monday to Friday and has weekends off.\",\n",
    "    \"Tom\": \"Tom is a policeman. He is busy every day and needs to be \" \\\n",
    "                + \"responsible for the security of the town, so he patrols the town every day.\",\n",
    "    \"Lee\": \"Lee is a recent college graduate who just moved to this small town.\"\n",
    "}\n",
    "town_areas_name = list(town_areas.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22b26f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "world_graph = nx.Graph()\n",
    "for town_area in town_areas.keys():\n",
    "    world_graph.add_node(town_area)\n",
    "    world_graph.add_edge(town_area, town_area)\n",
    "    \n",
    "for town_area in town_areas.keys():\n",
    "    if \"House\" in town_area:\n",
    "        world_graph.add_edge(town_area, \"Second Street\")\n",
    "    else:\n",
    "        world_graph.add_edge(town_area, \"Main Street\")\n",
    "    \n",
    "world_graph.add_edge(\"Police Office\", \"City Hall\")\n",
    "\n",
    "locations = {}\n",
    "for i in town_people.keys():\n",
    "    locations[i] = \"{}'s House\".format(i)\n",
    "nx.draw(world_graph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc7057bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = {}\n",
    "for i in town_people.keys():\n",
    "    memories[i] = []\n",
    "# memories[\"Jack\"].append(\"Jack has to work at City Hall today and then do some shopping.\")\n",
    "# memories[\"Tom\"].append(\"Tom has to work today and needs to patrol the town.\")\n",
    "# memories[\"Lee\"].append(\"Lee just moved to town yesterday. He planned to visit the town and do some shopping.\")\n",
    "\n",
    "plans = {}\n",
    "for i in town_people.keys():\n",
    "    plans[i] = []\n",
    "    \n",
    "week_time = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "weather = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c614d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_time = 8\n",
    "\n",
    "compressed_memories_all = {}\n",
    "for name in town_people.keys():\n",
    "    compressed_memories_all[name] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35080880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 5 µs, total: 17 µs\n",
      "Wall time: 34.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# for name in town_people.keys():\n",
    "# #     prompt = \"\"\"\n",
    "# #         You are {}. {} You just woke up your home {} and went out.\n",
    "# #         Today, this is {}'s plan, {}\n",
    "# #         What is your goal for today? \n",
    "# #         Be brief, and use at most 20 words and answer from your perspective.\n",
    "# #     \"\"\".format(name, town_people[name], locations[name], name, memories[name])\n",
    "#     prompt = \"\"\"\n",
    "#         You are {}, your plan is {} And you are in {} and go out later.What will {} do today? \n",
    "#     \"\"\".format(i, plans[i], locations[i], i)\n",
    "#     plans[name] = generate(prompt_meta.format(prompt))\n",
    "#     print(name, plans[name])\n",
    "#     print(\"=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5c56ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in plans.keys():\n",
    "#     question = \"\"\"\n",
    "#         You are {}, your plan is {} And you are in {} and go out later.What will {} do today? \n",
    "#     \"\"\".format(i, plans[i], locations[i], i)\n",
    "#     print(generate(prompt_meta.format(question)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5203b605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack \n",
      "\n",
      "Jack will go to City Hall for work.\n",
      "=================\n",
      "Tom \n",
      "\n",
      "Tom will patrol the town today to ensure the security of the town.\n",
      "=================\n",
      "Lee \n",
      "\n",
      "Lee wakes up from bed, stretching his arms and yawns. He has been living in this small town for a week now, and he is still trying to find his way around. He looks around his room, seeing the unpacked boxes and the messy state of his desk. He sighs, knowing he needs to get up and start his day.\n",
      "\n",
      "Lee decides to take a shower and get dressed. He puts on a simple outfit of jeans and a t-shirt, and heads downstairs to make breakfast. He opens the fridge and sees that he has some leftovers from last night's dinner, so he decides to heat those up in the microwave. While he waits for the food to cook, he checks his phone for any important messages.\n",
      "\n",
      "After a few minutes, the microwave beeps, and Lee takes out his breakfast. He grabs a plate and sits down at the table, taking a bite of his food. He closes his eyes in satisfaction, enjoying the taste of his meal.\n",
      "\n",
      "Lee spends the rest of the morning browsing social media, scrolling through his feeds and reading news articles. He also checks his email, seeing if he has any important messages or job offers. After a while, he feels like he has wasted enough time, and dec\n",
      "=================\n",
      "Jack \n",
      "\n",
      "I will go to City Hall for work.\n",
      "=================\n",
      "Tom \n",
      "\n",
      "Tom will patrol the town.\n",
      "=================\n",
      "Lee \n",
      "\n",
      "Lee will continue to explore the town and get to know the locals. He decides to go for a walk around the town, hoping to stumble upon some interesting places or people. He walks for about 30 minutes, taking in the sights and sounds of the town. Along the way, he passes by a small café and decides to go inside to grab a coffee and do some people-watching. As he sits at a table, he strikes up a conversation with the café owner, who tells him about the town's history and culture. Lee learns that the town has a rich history dating back centuries, and that many of the locals are descendants of the original settlers. He also discovers that the café is famous for its homemade pastries and cakes, and decides to try one of each. After finishing his coffee and pastry, Lee leaves the café and continues his walk around the town, feeling more connected to the place and its people. What will Lee do next?\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "for count in range(2):\n",
    "    for i in town_people.keys():\n",
    "        place = \"\"\n",
    "        if count == 0:\n",
    "            prompt = \"\"\"\n",
    "                    You are {}, {} and you are in {} and go out later.What will {} do today? \n",
    "                    \"\"\".format(i, town_people[i], locations[i], i)\n",
    "            plans[i] = generate(prompt_meta.format(prompt))\n",
    "            print(i, plans[i])\n",
    "            print(\"=================\")\n",
    "        \n",
    "            ### next place check\n",
    "            \n",
    "            place_prompt = \"\"\"\n",
    "                        You are {}, your plan is {}, right now you are in {}. Where shoule {} go next?\n",
    "                        \"\"\".format(i, plans[i], locations[i], i)\n",
    "            place = generate(place_prompt)\n",
    "            print(\"You are {}, and in {}, I will move to {} next\".format(i, locations[i]), place)\n",
    "            \n",
    "            ### action check\n",
    "            action_prompt = \"\"\"\n",
    "                                \n",
    "                            \"\"\".format()\n",
    "            action = generate(action_prompt)\n",
    "            print()\n",
    "            locations[i] = place\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            prompt = \"\"\"\n",
    "                    You are {}, your plan is {}. Now, it is {}:00, you are in {}.What will {} do here? \n",
    "                    \"\"\".format(i, plans[i], global_time, locations[i], i)\n",
    "            plans[i] = generate(prompt_meta.format(prompt))\n",
    "            print(i, plans[i])\n",
    "            print(\"=================\")\n",
    "            \n",
    "            \n",
    "            ### next place check\n",
    "            place_prompt = \"\"\"\n",
    "                        You are {}, your plan is {}, right now you are in {}. \n",
    "                        Where shoule {} go next or do not move?\n",
    "                        \"\"\".format(i, plans[i], locations[i], i)\n",
    "            place = generate(place_prompt)\n",
    "            locations[i] = place\n",
    "            \n",
    "            \n",
    "#             if len(set(list(locations.values()))) < len(locations.values()):\n",
    "            for town_name, people_list in town_location_have.items():\n",
    "                if len(town_location_have[town_name]) > 1:\n",
    "                    ### build prompt, do we add plans or memory, or both. \n",
    "                    action_promt = \"\"\"\n",
    "                                    You are {}, and in {}, {} stay here, too. \n",
    "                                    \"\"\".format(person, town_name, \", \".join(people_list[1: ]))\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                if len(town_location_have[town_name]) == 1:\n",
    "                    ### build prompt, do we add plans or memory, or both. \n",
    "                    action_promt = \"\"\"\n",
    "                                    You are {}, and in {}. \n",
    "                                    \"\"\".format(person, town_name)\n",
    "                    ### model build\n",
    "                        \n",
    "            \n",
    "            \n",
    "            ### action check\n",
    "#             else:\n",
    "#                 action_prompt = \"\"\"\n",
    "                                \n",
    "#                             \"\"\".format()\n",
    "#                 action = generate(action_prompt)\n",
    "    global_time += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a8358a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jack': [], 'Tom': [], 'Lee': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7f7cf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack \n",
      "\n",
      "You have chosen to tell the mayor about your plan to take over the town's government.\n",
      "\n",
      "\"Good morning, Mayor,\" you say, approaching the desk. \"I hope you're doing well. I have a proposal for you. I've been thinking about taking over the town's government, and I believe I have a plan that could benefit both of us.\"\n",
      "\n",
      "The mayor looks at you skeptically. \"I'm afraid that's not possible, Jack. The government is in place to serve the people, and it's not something that can be taken over by one person.\"\n",
      "\n",
      "You can see the disappointment in the mayor's eyes, but you're not giving up yet. You have several options for how to proceed:\n",
      "\n",
      "A) Try to persuade the mayor to see things your way.\n",
      "B) Offer to help the mayor with a specific problem or issue in exchange for his support.\n",
      "C) Use your knowledge of the town's gossip and rumors to try to gather information about the mayor's weaknesses.\n",
      "D) Use your charm and wit to try to win the mayor's trust.\n",
      "E) Try to find a way to bypass the mayor and go straight to the people.\n",
      "Please pick one of the options above by typing the corresponding letter.\n",
      "\n",
      "---\n",
      "\n",
      "What will you do?\n",
      "=================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_382/3838631081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                         \u001b[0mYou\u001b[0m \u001b[0mare\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myour\u001b[0m \u001b[0mplan\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0mnow\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mWhere\u001b[0m \u001b[0mshoule\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0mgo\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;31m?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \"\"\".format(i, plans[i], locations[i], i)\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You are {}, and in {}, I will move to {} next\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_382/443185229.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(prompt, use_openai)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                 device_map='auto')\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'### Response:'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m               \u001b[0mids\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \"\"\"\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     def preprocess(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1138\u001b[0m             )\n\u001b[1;32m   1139\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0;31m# 13. run sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             return self.sample(\n\u001b[0m\u001b[1;32m   1720\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2800\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2801\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2802\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1035\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_proj_slices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretraining_tp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/nn/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py\u001b[0m in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatMul4Bit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_context\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_SingleLevelFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, A, B, out, bias, quant_state)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;31m# 1. Dequantize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# 2. MatmulnN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdequantize_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# 3. Save state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for count in range(2):\n",
    "    if count == 0:\n",
    "        for i in town_people.keys():\n",
    "            prompt = \"\"\"\n",
    "                    You are {}, {} and you are in {} and go out later.What will {} do today? \n",
    "                    \"\"\".format(i, town_people[i], locations[i], i)\n",
    "            plans[i] = generate(prompt_meta.format(prompt))\n",
    "            print(i, plans[i])\n",
    "            print(\"=================\")\n",
    "            \n",
    "#             ### action check\n",
    "#             action_prompt = \"\"\"\n",
    "                                \n",
    "#                             \"\"\".format()\n",
    "#             action = generate(action_prompt)\n",
    "#             ####\n",
    "#             memories[i].append(action)\n",
    "#             ####\n",
    "#             print()\n",
    "        \n",
    "#             ### next place check\n",
    "            place_prompt = \"\"\"\n",
    "                        You are {}, your plan is {}, right now you are in {}. Where shoule {} go next?\n",
    "                        \"\"\".format(i, plans[i], locations[i], i)\n",
    "            place = generate(place_prompt)\n",
    "            print(\"You are {}, and in {}, I will move to {} next\".format(i, locations[i], place))\n",
    "            \n",
    "            locations[i] = place\n",
    "    else:\n",
    "        town_place_people_have = {}\n",
    "        for key, values in locations.items():\n",
    "            if key in town_place_people_have.keys():\n",
    "                town_place_people_have[values].append(key)\n",
    "            else:\n",
    "                town_place_people_have[values] = []\n",
    "                town_place_people_have[values].append(key)\n",
    "         \n",
    "#          for k, v in town_place_people_have.items():\n",
    "#             if len(v) > 1:\n",
    "#                 ### on prompt, which part should we add? memory, plans, or both?\n",
    "#                 ### do we need chatbot here, or just action add\n",
    "#                 prompt = \"\"\"\n",
    "#                          Now, there is {}, {} are there. \n",
    "#                          \"\"\".format(k, \", \".join(v))\n",
    "#                 ### model\n",
    "                \n",
    "                \n",
    "#                 ### next place check, will the person go to next new place or still here\n",
    "            \n",
    "#             else:\n",
    "#                 action_prompt = \"\"\"\"\"\"\n",
    "#                 ### model\n",
    "#                 #### memories[i].append(action)\n",
    "                \n",
    "        \n",
    "        if global_time == 23:\n",
    "            global_time = 0\n",
    "        else: \n",
    "            global_time += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c241372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jack': [], 'Tom': [], 'Lee': []}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6fc7c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack \n",
      "\n",
      "Jack will go to City Hall for work.\n",
      "=================\n",
      "You are Jack, and in Jack's House, you will move to \n",
      "\n",
      "City Hall next\n",
      "Tom \n",
      "\n",
      "Tom will patrol the town to ensure the security of the town.\n",
      "=================\n",
      "You are Tom, and in Tom's House, you will move to \n",
      "\n",
      "Patrol Town next\n",
      "Lee \n",
      "\n",
      "Lee wakes up early in the morning, feeling refreshed after a good night's sleep. They decide to start their day by going for a run in the nearby park. The fresh air and scenic views help them clear their mind and get a good workout. After their run, Lee returns home and takes a quick shower to freshen up.\n",
      "\n",
      "Next, Lee decides to explore the town and get a feel for the local culture. They walk around the main street, admiring the historic buildings and quaint shops. Along the way, they stop at a cozy café for a cup of coffee and a light breakfast.\n",
      "\n",
      "As the morning wears on, Lee receives a call from an old friend who invites them to a barbecue at a nearby lake. Lee decides to join the fun and spends the afternoon grilling and socializing with their friends.\n",
      "\n",
      "As the sun begins to set, Lee returns home, feeling content and fulfilled after a productive and enjoyable day. They spend the evening relaxing and catching up on some reading before going to bed, feeling grateful for the simple pleasures in life.\n",
      "=================\n",
      "You are Lee, and in Lee's House, you will move to \n",
      "\n",
      "Lee's House next\n"
     ]
    }
   ],
   "source": [
    "for i in town_people.keys():\n",
    "    prompt = \"\"\"\n",
    "                    You are {}, {} and you are in {} and go out later.What will {} do today? \n",
    "                    \"\"\".format(i, town_people[i], locations[i], i)\n",
    "    plans[i] = generate(prompt_meta.format(prompt))\n",
    "    print(i, plans[i])\n",
    "    print(\"=================\")\n",
    "    \n",
    "    place_prompt = \"\"\"\n",
    "                        You are {}, your plan is {}, right now you are in {}. you can go to{} Where shoule you go next?\n",
    "                        Be brief, and use at most 3 words and answer from your perspective.\n",
    "                        \"\"\".format(i, plans[i], locations[i], \", \".join(town_areas_name))\n",
    "    place = generate(prompt_meta.format(place_prompt))\n",
    "    print(\"You are {}, and in {}, you will move to {} next\".format(i, locations[i], place))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a40cdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Town Exit',\n",
       " 'Main Street',\n",
       " 'Second Street',\n",
       " 'City Hall',\n",
       " 'Police Office',\n",
       " 'Park',\n",
       " 'Supermarket',\n",
       " \"Jack's House\",\n",
       " \"Tom's House\",\n",
       " \"Lee's House\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "town_areas_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eecf3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11168b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38c12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c578a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9d2809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_prompts = {}\n",
    "for location in town_areas.keys():\n",
    "    people = []\n",
    "    for i in town_people.keys():\n",
    "        if locations[i] == location:\n",
    "            people.append(i)\n",
    "            \n",
    "    for name in people:\n",
    "        prompt = \"You are {}. {} You are planning to: {}. You are currently in {} with the following description: {}. It is currently {}:00. The following people are in this area: {}. You can interact with them.\".format(name, town_people[name], plans[name], location, town_areas[location], str(global_time), ', '.join(people))\n",
    "        people_description = []\n",
    "        for i in people:\n",
    "            people_description.append(i+': '+town_people[i])\n",
    "            prompt += ' You know the following about people: ' + '. '.join(people_description)\n",
    "            memory_text = '. '.join(memories[name][-10:])\n",
    "            prompt += \"What do you do in the next hour? Use at most 10 words to explain.\"\n",
    "            action_prompts[name] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d12dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_results = {}\n",
    "for name in town_people.keys():\n",
    "    action_results[name] = generate(prompt_meta.format(action_prompts[name]))\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Convert the following paragraph to first person past tense:\n",
    "    \"{}\"\n",
    "    \"\"\".format(action_results[name])\n",
    "    action_results[name] = generate(prompt_meta.format(prompt)).replace('\"', '').replace(\"'\", '')\n",
    "    print(name, action_results[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_prompts = {}\n",
    "for location in town_areas.keys():\n",
    "    people = []\n",
    "    for i in town_people.keys():\n",
    "        if locations[i] == location:\n",
    "            people.append(i)\n",
    "  \n",
    "    for name in people:\n",
    "        for name_two in people:\n",
    "            memories[name].append('[Time: {}. Person: {}. Memory: {}]\\n'.format(str(global_time), \n",
    "                                                                                name_two, \n",
    "                                                                                action_results[name_two]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac9ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92701a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_rating(x):\n",
    "    nums = [int(i) for i in re.findall(r'\\d+', x)]\n",
    "    if len(nums)>0:\n",
    "        return min(nums)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef12c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_ratings = {}\n",
    "for name in town_people.keys():\n",
    "    memory_ratings[name] = []\n",
    "    for i, memory in enumerate(memories[name]):\n",
    "        prompt = \"You are {}. Your plans are: {}. You are currently in {}. It is currently {}:00. You observe the following: {}. Give a rating, between 1 and 5, to how much you care about this.\".format(name, plans[name], locations[name], str(global_time), memory)\n",
    "        res = generate(prompt_meta.format(prompt))\n",
    "        rating = get_rating(res)\n",
    "        max_attempts = 2\n",
    "        current_attempt = 0\n",
    "        while rating is None and current_attempt<max_attempts:\n",
    "            rating = get_rating(res)\n",
    "            current_attempt += 1\n",
    "        if rating is None:\n",
    "            rating = 0\n",
    "        memory_ratings[name].append((res, rating))\n",
    "    print(memory_ratings[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b60e6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544892d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
